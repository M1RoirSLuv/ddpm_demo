import torch
import numpy as np
from PIL import Image
import torchvision.transforms as transforms
from diffusers import UNet2DModel, DDPMScheduler
from omegaconf import OmegaConf
from ldm.util import instantiate_from_config
import os


# 1. åŠ è½½ç»„ä»¶ (å‚è€ƒ test.py å’Œ train_new.py)
def load_models(vae_config, vae_ckpt, unet_weights, device):
    # åŠ è½½ VAE
    config = OmegaConf.load(vae_config)
    vae = instantiate_from_config(config.model)
    vae.load_state_dict(torch.load(vae_ckpt, map_location="cpu")["state_dict"], strict=False)
    vae.to(device).eval()

    # åŠ è½½ UNet
    unet = UNet2DModel(
        sample_size=(256, 320),
        in_channels=3,
        out_channels=3,
        layers_per_block=2,
        block_out_channels=(128, 256, 512, 512),
        down_block_types=("DownBlock2D", "DownBlock2D", "AttnDownBlock2D", "DownBlock2D"),
        up_block_types=("UpBlock2D", "AttnDownBlock2D", "UpBlock2D", "UpBlock2D"),
    )
    unet.load_state_dict(torch.load(unet_weights, map_location="cpu"))
    unet.to(device).eval()

    return vae, unet


def reconstruct_verify():
    # --- é…ç½® ---
    IMG_PATH = "data/raw/test.jpg"  # é€‰ä¸€å¼ è®­ç»ƒé›†é‡Œçš„åŸå›¾
    UNET_WEIGHTS = "./checkpoints/unet_epoch_10.pth"
    VAE_CONFIG = "vae_config.yaml"
    VAE_CKPT = "model/autoencoder.ckpt"
    DEVICE = "cuda"

    vae, unet = load_models(VAE_CONFIG, VAE_CKPT, UNET_WEIGHTS, DEVICE)
    scheduler = DDPMScheduler(num_train_timesteps=1000)

    # 2. å¤„ç†åŸå›¾å¹¶ç¼–ç åˆ°æ½œç©ºé—´ (å‚è€ƒ test.py)
    img = Image.open(IMG_PATH).convert("RGB")
    transform = transforms.Compose([
        transforms.Resize((1024, 1280)),  # å¯¹åº” 1280x1024
        transforms.ToTensor(),
        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
    ])
    x = transform(img).unsqueeze(0).to(DEVICE)

    with torch.no_grad():
        # è·å–åŸå›¾çš„æ½œç‰¹å¾
        clean_latents, _, _ = vae.encode(x)

        # 3. æ¨¡æ‹ŸåŠ å™ª (éªŒè¯é‡å»ºèƒ½åŠ›ï¼Œæˆ‘ä»¬å¯ä»¥åŠ  500 æ­¥å™ªå£°ï¼Œçœ‹çœ‹æ¨¡å‹èƒ½å¦è¿˜åŸå›å»)
        noise = torch.randn_like(clean_latents)
        timesteps = torch.tensor([500]).long().to(DEVICE)  # è®¾ç½®ä¸€ä¸ªä¸­é—´æ­¥æ•°
        noisy_latents = scheduler.add_noise(clean_latents, noise, timesteps)

        # 4. é€æ­¥å»å™ª (ä»ç¬¬ 500 æ­¥å›åˆ°ç¬¬ 0 æ­¥)
        print("ğŸ”„ æ­£åœ¨å°è¯•ä»å™ªå£°é‡å»ºåŸå›¾...")
        scheduler.set_timesteps(1000)
        # è¿‡æ»¤å‡ºå°äºç­‰äº 500 çš„æ—¶é—´æ­¥
        active_timesteps = scheduler.timesteps[scheduler.timesteps <= 500]

        curr_latents = noisy_latents
        for t in active_timesteps:
            # é¢„æµ‹å™ªå£°å¹¶å»å™ª
            noise_pred = unet(curr_latents, t).sample
            curr_latents = scheduler.step(noise_pred, t, curr_latents).prev_sample

        # 5. VAE è§£ç å›åƒç´ 
        reconstruction = vae.decode(curr_latents)
        reconstruction = (reconstruction / 2 + 0.5).clamp(0, 1)

    # ä¿å­˜å¯¹æ¯”ç»“æœ
    res = reconstruction.cpu().permute(0, 2, 3, 1).numpy()[0]
    res_img = Image.fromarray((res * 255).astype(np.uint8))
    res_img.save("reconstruction_verify.png")
    print("âœ… é‡å»ºéªŒè¯å®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³ reconstruction_verify.png")


if __name__ == "__main__":
    reconstruct_verify()
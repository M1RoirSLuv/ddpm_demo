import torch
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from diffusers import UNet2DModel, DDPMScheduler
from accelerate import Accelerator
import os
from tqdm import tqdm


# 1. å®šä¹‰æ½œç©ºé—´æ•°æ®é›†
class LatentDataset(Dataset):
    def __init__(self, latent_dir):
        # è‡ªåŠ¨åŠ è½½ä¹‹å‰é¢„å¤„ç†å¥½çš„ .pt æ–‡ä»¶
        self.files = [os.path.join(latent_dir, f) for f in os.listdir(latent_dir) if f.endswith('.pt')]
        if len(self.files) == 0:
            raise RuntimeError(f"åœ¨ {latent_dir} ä¸­æ²¡æ‰¾åˆ°ä»»ä½• .pt æ–‡ä»¶ï¼")
        print(f"ğŸ“Š åŠ è½½äº† {len(self.files)} ä¸ªæ½œç©ºé—´ç‰¹å¾æ–‡ä»¶")

    def __len__(self):
        return len(self.files)

    def __getitem__(self, idx):
        # åŠ è½½å½¢çŠ¶ä¸º [3, 256, 320] çš„å¼ é‡
        return torch.load(self.files[idx])


# 2. è®­ç»ƒä¸»å‡½æ•°
def train():
    # --- è¶…å‚æ•°è®¾ç½® ---
    LATENT_DIR = "./data/latents"
    OUTPUT_DIR = "./checkpoints"
    BATCH_SIZE = 2  # å¦‚æœæ˜¾å­˜å¤Ÿå¤§ï¼Œå¯ä»¥æ”¹ä¸º 4
    GRADIENT_ACCUM = 4  # æ¢¯åº¦ç´¯ç§¯ï¼Œç›¸å½“äº Batch Size = 2*4=8
    LEARNING_RATE = 1e-4
    EPOCHS = 100
    # ------------------

    # åˆå§‹åŒ–åŠ é€Ÿå™¨ (è‡ªåŠ¨å¤„ç† FP16 å’Œå¤šå¡ç¯å¢ƒ)
    accelerator = Accelerator(
        mixed_precision="fp16",
        gradient_accumulation_steps=GRADIENT_ACCUM
    )

    # æ•°æ®åŠ è½½
    dataset = LatentDataset(LATENT_DIR)
    train_dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)

    # åˆå§‹åŒ– UNet
    # sample_size å¯¹åº”æ½œç©ºé—´åˆ†è¾¨ç‡ (H, W)
    model = UNet2DModel(
        sample_size=(256, 320),
        in_channels=3,
        out_channels=3,
        layers_per_block=2,
        block_out_channels=(128, 256, 512, 512),  # å¢åŠ é€šé“æ•°ä»¥æå–å¤æ‚ç‰¹å¾
        down_block_types=(
            "DownBlock2D",
            "DownBlock2D",
            "AttnDownBlock2D",  # åœ¨ä½åˆ†è¾¨ç‡å±‚åŠ å…¥ Attention
            "DownBlock2D"
        ),
        up_block_types=(
            "UpBlock2D",
            "AttnUpBlock2D",
            "UpBlock2D",
            "UpBlock2D"
        ),
    )

    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)
    noise_scheduler = DDPMScheduler(num_train_timesteps=1000)

    # ä½¿ç”¨ accelerator å‡†å¤‡æ‰€æœ‰ç»„ä»¶
    model, optimizer, train_dataloader = accelerator.prepare(model, optimizer, train_dataloader)

    os.makedirs(OUTPUT_DIR, exist_ok=True)

    print("ğŸ”¥ å¼€å§‹è®­ç»ƒ...")
    for epoch in range(EPOCHS):
        model.train()
        progress_bar = tqdm(total=len(train_dataloader), disable=not accelerator.is_local_main_process)
        progress_bar.set_description(f"Epoch {epoch}")

        for step, batch in enumerate(train_dataloader):
            with accelerator.accumulate(model):
                clean_latents = batch  # å½¢çŠ¶ [B, 3, 256, 320]

                # é‡‡æ ·å™ªå£°
                noise = torch.randn_like(clean_latents)
                bs = clean_latents.shape[0]

                # éšæœºé‡‡æ ·æ—¶é—´æ­¥
                timesteps = torch.randint(0, noise_scheduler.config.num_train_timesteps, (bs,),
                                          device=clean_latents.device).long()

                # å‰å‘åŠ å™ª
                noisy_latents = noise_scheduler.add_noise(clean_latents, noise, timesteps)

                # é¢„æµ‹å™ªå£°
                noise_pred = model(noisy_latents, timesteps).sample

                # è®¡ç®—æŸå¤± (MSE)
                loss = F.mse_loss(noise_pred, noise)

                # åå‘ä¼ æ’­
                accelerator.backward(loss)
                optimizer.step()
                optimizer.zero_grad()

            progress_bar.update(1)
            progress_bar.set_postfix(loss=loss.item())

        # å®šæœŸä¿å­˜
        if epoch % 10 == 0:
            accelerator.wait_for_everyone()
            if accelerator.is_main_process:
                # åªä¿å­˜ UNet æƒé‡
                unwrapped_model = accelerator.unwrap_model(model)
                torch.save(unwrapped_model.state_dict(), os.path.join(OUTPUT_DIR, f"unet_epoch_{epoch}.pth"))


if __name__ == "__main__":
    train()